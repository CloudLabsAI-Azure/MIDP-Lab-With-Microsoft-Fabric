# Exercise 4: Glimpse of Purview to govern the overall data and analytics estate. <a name="tee-up-the-purview"></a>

### Estimated Duration : 30 minutes

In Exercise 1, you loaded raw data into the Lakehouse. Then, in Exercise 2, you used a Delta Live Table pipeline to transform it into a data product for downstream consumption by analysts. 

In Exercise 3, you applied machine learning operations on this data product to build a customer sentiment model. This sentiment analysis allows Wide World Importers to determine which hashtags are trending so they can customize their campaigns to improve their sales while retaining their existing customers.

Meanwhile, Microsoft Purview provides a unified data governance service that helps manage and govern Wide World Importers’ data, which is stored in multi-cloud environments and in data sources such as Oracle, Teradata, ADLS Gen2, and Azure SQL Database.

In this exercise, you will explore the Wide World Importers data estate that’s registered in Microsoft Purview.

1. In the Azure portal web session (tab), In the search results pane, select **Microsoft Purview accounts**.

    ![](../media/img402.png)  

2. In the **Microsoft Purview accounts** page, select the resource that has a name starting with **purviewanalytics**.

    >**Note:** Each user has their own unique instance of this resource.

    ![](../media/img403.png) 

3. In the Microsoft Purview accounts resource page, to perform this task, the user needs to be added to root collection admin, to do that, select **Root collection permission (1)** from the left menu and click on **+ Add root collection admin (2)**.

   ![](../media/03/midp-img-11.png)

4. In the **Select Members** pane, search and select **ODL_User <inject key="DeploymentId"></inject> (1)** and click on **Apply (2)**.

   ![](../media/03/midp-img-12.png)

5. In the Microsoft Purview accounts resource page, in the **Open Microsoft Purview Governance Portal** tile, select the **Open** link.

   ![](../media/06/midp-img-6.png)

   *Microsoft Purview Governance Portal opens in a new web session (tab).*

6. In the Microsoft Purview Governance Portal web session (tab), at the top left expand the dashboard by clicking on the **>>**. 

   ![](../media/06/E4-S5.png)

7. Select **Data map (1)**, choose **collections (2)** from menu, ensure that **purviewanalytics (3)** collection is selected, under **Role assignments (4)** tab, click on shown **icon (5)** for **Data Source admins**.

   ![](../media/03/midp-img-13.png)

8. Please select the **ODL_User <inject key="DeploymentId"></inject>** and add as Data source admin.

7. Select the **Data map** icon and then select **Data Sources**.

   *Data map makes your data meaningful by graphing your data assets and their relationships across your data estate. Use a data map to discover data and manage access to that data.*

   ![](../media/06/E4-S6.png)

6. In the map view, for the root collection item, select the plus (+) icon to reveal the collections.

   ![](../media/image4009.png)

7. Expand each of the collections to review specific sources related to those collections.

   ![](../media/image4010.png) 

----

   > **Congratulations** on completing the task! Now, it's time to validate it. Here are the steps:
   > - If you receive a success message, you can proceed to the next task.
   > - If not, carefully read the error message and retry the step, following the instructions in the lab guide. 
   > - If you need any assistance, please contact us at cloudlabs-support@spektrasystems.com. We are available 24/7 to help you out.

   <validation step="6f4c5393-39ee-4d86-8efc-08c711b513da" />

Congratulations! You as Data Engineers, have helped Wide World Importers gain actionable insights from its disparate data sources, thereby contributing to future growth, customer satisfaction, and competitive advantage.

In this lab, we experienced the creation of a simple, integrated, open and governed Data Lakehouse foundation using the Microsoft Analytics Solution Pattern. 

In this lab, we covered the following: 
1.	First, we looked at data ingestion from a spectrum of analytical and operational data sources into the Lakehouse. We started with streaming data and analytics pipeline using ADX for a near real-time analytics scenario, followed by Synapse pipelines that ingested raw data from analytical/operational data sources to the Bronze layer. 

2.	Second, we explored offline data and analytics pipelines using open Delta format and Azure Databricks Delta Live Tables. We stitched streaming and non-streaming data (landed earlier) together, to create a combined data product to build a simple Lakehouse.

3.	Third, we explored ML and BI scenarios on the Lakehouse. Here we reviewed the MLOps pipeline using the Azure Databricks managed MLflow with Azure ML. Then, using Power BI with Synapse serverless SQL pool capabilities, we derived actionable insights. We explored SQL Analytics with Azure Databricks and Azure Synapse Serverless. 

4.  Finally, we leveraged Purview for data governance.  

## Summary

In this exercise, you have worked with Purview and how it governs the entire data and analytics estate, ensuring comprehensive data management and compliance

### You have successfully completed the lab
